<!DOCTYPE html>

<html>

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"> <!--https://stackoverflow.com/a/30709473-->
  <title>Research</title>
  <link rel="stylesheet" href="/assets/css/styles.css" />
  <link type="application/atom+xml" rel="alternate" href="/feed.xml" />
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Research</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Research" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Research" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Research","url":"/research/"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>
  <div id="content">
    <div class="banner">
  <div class="heading"><i class="fa fa-file-text-o"></i>Ideas and Investigations</div>

  <div class="filter-button-group">
    <span class="btn all active" data-filter="*">All</span>
    <span class="btn" data-filter=".ongoing">Ongoing Projects</span>
    <span class="btn" data-filter=".poster">Posters & LBWs</span>
    <span class="btn" data-filter=".workshop">Workshop Papers</span>
  </div>
</div>

<div class="grid">
  
  <div class="workshop">
    <a>
      <a href="/publications/2022-05-09-ecscw2022workshop.html">Accuracy and Anthropomorphism of AI on Trust</a>, ECSCW 2022 Workshop Position Paper
      

      <p>Artificial intelligence (AI) is increasingly used in digital products for a wide variety of purposes like content creation, recommendation, surveillance and judgment. With AI technologies designed with the intent of assisting humans becoming more common, understanding how users perceive and interact with AI becomes an important line of investigation. A key aspect is trust. Trust is concerned with the confidence users have in AI and their propensity to use it. While it may not necessarily translate into behavior, trust is integral in determining whether users will even consider using AI. With advances in AI research enabling AI systems to perform better and be designed in more realistic ways, we aim to look at how accuracy and anthropomorphism affect trust in AI. We have a study in plan and describe the design, inquiry and considerations of it.</p>

    </a>
  </div>
  
  <div class="workshop">
    <a>
      <a href="/publications/2022-04-23-chi2022workshop.html">Perceptions of Explanations in Automated Fact-Checkers</a>, CHI 2022 Workshop Position Paper
      
      <a href="https://www.dropbox.com/s/dwoxp7qmnj145te/HCXAI2022_paper_16.pdf?dl=0" target="_blank"><i class="fa fa-file"></i></a> <!--fa-download-->
      

      <p>Automated misinformation detection is commonly used in social media apps to surveil the chaotic and massive information space. Measures taken when misinformation is identifed include fagging, blocking, and removing of the content. When fagged, a fact-checking professional is alerted by the system to manually vet the content. When removed, users may see a label overlay on the content. In both cases, humans are at the receiving end of the action, yet opaque artifcial intelligence systems are unable to provide information on how the decision was made, making the decision questionable and doubtful. Explainable artifcial intelligence (XAI) has been proposed to address this. In considering the use of XAI for automated fact-checking, we discuss the rationale and design of a comparative study that seeks to understand users’ preferences and behaviors towards different explanations used in automated fact-checking with the goal of identifying design considerations.</p>

    </a>
  </div>
  
  <div class="poster">
    <a>
      <a href="/publications/2022-04-21-ecscw2022poster.html">Explanation Preferences in XAI Fact-Checkers</a>, ECSCW 2022 Poster
      

      <p>As misinformation grows rampantly, fact-checking has become an inordinate task that calls for automation. While there has been much advancement in the identification of misinformation using artificial intelligence (AI), these systems tend to be opaque, fulfilling little of what fact-checking does to convince users of its evaluation. A proposition for this is the use of explainable AI (XAI) to reveal the decision-making processes of the AI. As research on XAI fact-checkers accumulate, investigating user attitudes on the use of AI in fact-checking and towards different styles of explanations will contribute to an understanding of explanation preferences in XAI fact-checkers. We present the preliminary results of a perception study with 22 participants, finding a clear preference towards explanations mimicking organic fact-checking practices and towards explanations that use texts or that contain more details. These early findings may guide the design of XAI to enhance the performance of the human-AI system.</p>

    </a>
  </div>
  
  <div class="ongoing">
    <a>
      <a href="/publications/2022-06-21-projectB.html">Perceptions towards Explanations by XAI Fact-Checkers</a>, Ongoing Project
      

      <p>This project seeks to understand the preferences towards different styles of explanations in the context of automated fact-checkers on social media. It also investigates the effectiveness of the explanations on correcting news perceptions.</p>

    </a>
  </div>
  
  <div class="ongoing">
    <a>
      <a href="/publications/2022-06-21-projectA.html">Chatbot Intervention for Misinformation on Instant Messaging Apps</a>, Ongoing Project
      

      <p>This project seeks to understand the effectiveness of credibility labels on news provided by a fact-checking chatbot on instant messaging apps. It also looks at how trust in different fact-checkers affect perceptions towards the labels.</p>

    </a>
  </div>
  
  <div class="workshop">
    <a>
      <a href="/publications/2021-09-28-cscw2021workshop.html">Considering Human-Centeredness in Automated Fact-Checking</a>, CSCW 2021 Workshop Position Paper
      

      <p>Automated fact-checking has been used to address the tremendous volume of misinformation online. Engaging with the dialogue on human-centered AI, we consider the use of explainable AI for automated fact-checking. We discuss the research question, the design of a comparative study of explainable AI interfaces to aid in the investigation, and the potential implications on human-centered AI.</p>

    </a>
  </div>
  
  <div class="poster">
    <a>
      <a href="/publications/2021-07-18-cscw2021poster.html">Local Perceptions and Practices of News Sharing and Fake News</a>, CSCW 2021 Poster
      
      <a href="https://dl.acm.org/doi/10.1145/3462204.3481767" target="_blank"><i class="fa fa-file"></i></a> <!--fa-download-->
      

      <p>Fake news is a prevalent problem, particularly in digital media, that undermines trust and cooperation among people. As a variety of global mitigation efforts arise, the understanding of how people consider fake news becomes important, especially in local contexts. To that end, we carried out a survey with 75 participants in Singapore to understand people’s perceptions of and practices with news (real and fake). Locally, fake news was found to be more pervasive in instant messaging apps than in social media, with the problem attributed more strongly to sharing than to creation. Good news sharing practices were generally observed. Highest trust was reported in government communication platforms across 11 media items. These results show that Singapore possesses a peculiar sociocultural scene, suggesting that efforts directed towards locally relevant measures may be more effective in addressing fake news in Singapore. We detail the survey results and recommended directions in this paper.</p>

    </a>
  </div>
  
  <div class="workshop">
    <a>
      <a href="/publications/2020-10-03-cscw2020workshopB.html">Perceptions of News Sharing and Fake News in Singapore</a>, CSCW 2020 Workshop Position Paper
      
      <a href="https://cscwcivictechnologies.files.wordpress.com/2020/10/perceptions_of_news_sharing_and_fakenews_in_singapore.pdf" target="_blank"><i class="fa fa-file"></i></a> <!--fa-download-->
      

      <p>Fake news is a prevalent problem that can undermine citizen engagement and become an obstacle to the goals of civic tech. To understand consumers’ reactions and actions towards fake news, and their trust in various news media, we conducted a survey in Singapore. We found that fake news stem largely from instant messaging apps and social media, and that the problem of fake news was attributed more to its sharing than to its creation. Verification of news was done mainly by using a search engine to check and cross-reference the news. Amongst the top three sources to obtain news, there was low trust reported in social media, high trust in local news channels, and highest trust in government communication platforms. The strong trust in government communication platforms suggests that top-down civic tech initiatives may have great potential to effectively manage fake news and promote citizen engagement in Singapore.</p>

    </a>
  </div>
  
  <div class="workshop">
    <a>
      <a href="/publications/2020-10-03-cscw2020workshopA.html">#CivicTech For And By Citizens: A Review And A Meta-Evaluation</a>, CSCW 2020 Workshop Position Paper
      
      <a href="https://cscwcivictechnologies.files.wordpress.com/2020/10/civictech_for_and_by_citizens.pdf" target="_blank"><i class="fa fa-file"></i></a> <!--fa-download-->
      

      <p>This paper takes a first step to systematically review and collectively evaluate #CivicTech works done in the computer science discipline, especially the vibrant community of CSCW. Based on 50 full papers published in CSCW, we ran a quantitative content analysis of the works. We found that civic tech is a growing young field with interests from all over the world, across academic, governmental, and commercial sections. While we are progressing well towards the goal of “for the citizens”, “by the citizens” remains largely absent. We call for a more balanced approach to civic tech, both in developing cutting edge technologies and in adapting laymen and popular technologies for civic purposes.</p>

    </a>
  </div>
  
</div>

<script src="https://code.jquery.com/jquery-3.1.0.min.js"
  integrity="sha256-cCueBR6CsyA4/9szpPfrX3s49M9vUU5BgtiJj06wt/s=" crossorigin="anonymous"></script>
<script src="https://unpkg.com/isotope-layout@3.0/dist/isotope.pkgd.js"></script>

<script>
  var $grid = $(".grid").on(function () {
    $grid.isotope({});
  });
  $(".filter-button-group").on("click", "span", function () {
    var filterValue = $(this).attr("data-filter");
    $grid.isotope({ filter: filterValue });
  });
  $(".btn").on("click", function () {
    $(".btn").removeClass("active");
    $(this).addClass("active");
  });
</script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </div>

  <nav>
  
  <a href="/" >Home</a>
  
  <a href="/research/" class="current" >Research</a>
  
  <a href="/contact/" >Contact</a>
  
</nav>

  <footer>
    © 2022 Gionnieve Lim<!--. All rights reserved.-->
  </footer>
</body>

</html>